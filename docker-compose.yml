version: '3.14'

services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: lfb_api
    ports:
      - "8000:8000"
    environment:
      - SECRET_KEY=${SECRET_KEY}
      - ALGORITHM=${ALGORITHM}
      - PYTHONPATH=${PYTHONPATH}
      - MONGO_URI=${MONGO_URI}
      - PROMETHEUS_METRICS=True
    depends_on:
      - mongodb
    networks:
      - lfb_network

  mongodb:
    image: mongo:4.4
    container_name: mongodb
    restart: always
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}
    ports:
      - "27017:27017"
    networks:
      - lfb_network
    command: ["mongod", "--auth", "--bind_ip_all", "--port", "27017"]
    healthcheck:
      test: ["CMD", "mongo", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  airflow-webserver:
    build:
      context: ./airflow  
      dockerfile: Dockerfile.airflow  
    container_name: airflow
    restart: always
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor  
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////home/airflow/airflow.db
      - AIRFLOW_CONN_MONGO_CONN=${MONGO_URI}
      - AIRFLOW__CORE__FERNET_KEY=${FERNET_KEY}
      - PYTHONPATH=/opt/airflow/app:/opt/airflow:/home/airflow/.local/lib/python3.12/site-packages
    ports:
      - "8080:8080"
    networks:
      - lfb_network
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - airflow_logs:/opt/airflow/logs
      - airflow_db:/home/airflow
      - ./app:/opt/airflow/app
      - ./model:/opt/airflow/model
      - ./airflow/airflow.cfg:/opt/airflow/airflow.cfg
    entrypoint: ["bash", "-c", "airflow db migrate && airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password psw && airflow webserver"]

  airflow-scheduler:
    build:
      context: ./airflow
      dockerfile: Dockerfile.airflow
    container_name: airflow_scheduler
    restart: always
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////home/airflow/airflow.db
      - AIRFLOW_CONN_MONGO_CONN=${MONGO_URI}
      - AIRFLOW__CORE__FERNET_KEY=${FERNET_KEY}
      - PYTHONPATH=/opt/airflow/app:/opt/airflow:/home/airflow/.local/lib/python3.12/site-packages
    networks:
      - lfb_network
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - airflow_logs:/opt/airflow/logs
      - airflow_db:/home/airflow
      - ./app:/opt/airflow/app
      - ./model:/opt/airflow/model
      - ./airflow/airflow.cfg:/opt/airflow/airflow.cfg
    entrypoint: ["bash", "-c", "airflow db migrate && airflow scheduler"]

  prometheus:
    image: prom/prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    networks:
      - lfb_network

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
    volumes:
      - ./grafana:/var/lib/grafana
    networks:
      - lfb_network


networks:
  lfb_network:
    driver: bridge

volumes:
  dags:
  airflow_logs:
  airflow_db:
  grafana_data: